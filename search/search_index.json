{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"about/about/","title":"Team","text":"<ul> <li>Annus Zulfiqar</li> <li>Ali Imran</li> <li>Venkat Kunaparaju</li> <li>Ben Pfaff</li> <li>Gianni Antichi</li> <li>Muhammad Shahbaz</li> </ul>"},{"location":"about/release-notes/","title":"Release Notes","text":""},{"location":"deepdive/architecture/","title":"Gigaflow Architecture in OVS","text":""},{"location":"deepdive/fast-path/","title":"Gigaflow Fast Path","text":""},{"location":"deepdive/slow-path/","title":"Gigaflow Slow Path","text":""},{"location":"getting-started/demo/","title":"Project Demo","text":""},{"location":"getting-started/installation/","title":"Installation","text":"<p>Dependencies</p> <p>All dependencies and their installation is managed via Ansible which we run through a <code>docker</code> container. The only required dependency for this setup is <code>docker</code>. Follow the steps specified at this link and then allow non-root users to use docker by following these steps.</p>"},{"location":"getting-started/installation/#testbed-setup","title":"Testbed Setup","text":"<p>The testbed setup requires 3 machines: </p> Figure 2: The Expected Testbed Setup for Running Gigaflow Artifact <ul> <li>Collector (to store rulesets/traces and collect logs)</li> <li>GvS Device-under-Test (to run <code>gvs</code>)</li> <li>Tgen (to send/receive traffic)</li> </ul> <p>The physical resources required on each machine are labeled on Figure 2.</p> <p>Tip</p> <p>These three machines can also be VMs running on the same physical host. The experiments in the paper were performed where the Ansible orchestrator was running on the same machine as <code>gvs</code> but it could also run on the <code>tgen</code> or the collector machine. The collector can be the same VM/machine running <code>gvs</code> or <code>tgen</code>. Finally, the memory and CPU requirements might seem bloated because of the test setup used for experiments. You should be able to run with much fewer resources (e.g. 16 cores, 16GB RAM) as long as the Intel XL710 10/40G NICs are available.</p>"},{"location":"getting-started/installation/#testbed-configuration","title":"Testbed Configuration","text":"<p>We use Ansible to orcherstrate all experiments using these three machines. Therefore, we require <code>root</code> access to each of them. To populate for each machine, update the <code>inventory.ini</code> file as following:</p> inventory.ini<pre><code>[NODES]\nTGEN ansible_host=&lt;tgen-ip&gt; ansible_user=&lt;tgen-username&gt; ansible_password=&lt;tgen-password&gt; ansible_sudo_pass=&lt;tgen-root-password&gt;\nGVS ansible_host=&lt;ovs-ip&gt; ansible_user=&lt;ovs-username&gt; ansible_password=&lt;ovs-password&gt; ansible_sudo_pass=&lt;ovs-root-password&gt;\n\n[STORAGE]\nCOLLECTOR ansible_host=&lt;collector-ip&gt; ansible_user=&lt;collector-username&gt; ansible_password=&lt;collector-password&gt; ansible_sudo_pass=&lt;collector-root-password&gt; ansible_ssh_user=&lt;collector-username&gt; ansible_ssh_pass=&lt;collector-root-password&gt;\n</code></pre>"},{"location":"getting-started/overview/","title":"Overview","text":"<p>The Gigaflow artifact is available publicly on Github. All vSwitch pipelines along with the traffic traces used for evaluation are also available via FigShare.</p> Figure 1: The End-to-End Gigaflow Artifact <p>With our artifact, we share the ansible playbooks and the source code for the various components of the Gigaflow OvS framework as described in the ASPLOS 25 paper.</p> <ul> <li>OVS Gigaflow - https://github.com/gigaflow-vswitch/gvs.git</li> <li>Traffic Generator - https://github.com/gigaflow-vswitch/tgen.git</li> </ul>"},{"location":"home/home/","title":"Gigaflow Virtual Switch (GvS)","text":""},{"location":"home/home/#the-gigaflow-project","title":"The Gigaflow Project","text":"<p>Gigaflow is a multi-table cache architecture for the Open vSwitch that captures pipeline-aware locality from the vSwitch pipelines in addition to the temporal and spatial locality captured by traditional caches (e.g., Microflow and Megaflow in OvS).  This allows Gigaflow to deliver significantly higher hit rate and lower per-packet end-to-end latency. Unlike traditional caches that capture entire traversals as cache entries, Gigaflow determines the most suitable sub-traversals that could be shared among many flows, thereby capturing a cross-product rule space in the cache.</p> Figure 1: Gigaflow Cache in Open vSwitch"},{"location":"home/home/#the-documentation","title":"The Documentation","text":"<p>This documentation will take you through the official Gigaflow ASPLOS 2025 artifact. It elaborates how to setup and install Gigaflow with Open vSwitch, generate vSwitch pipelines and traffic flows, how to run the automated experiment scripts (based on Ansible), and how to view the results.</p>"},{"location":"home/publications/","title":"Publications","text":"<p>ASPLOS 2025 Gigaflow: Pipeline-Aware Sub-Traversal Caching for Modern SmartNICs Annus Zulfiqar, Ali Imran, Venkat Kunaparaju, Ben Pfaff, Gianni Antichi, Muhammad Shahbaz</p> <p>Hot Chips 2024 Gigaflow: A Smart Cache for a SmartNIC! Annus Zulfiqar, Ali Imran, Venkat Kunaparaju, Ben Pfaff, Gianni Antichi, Muhammad Shahbaz</p> <p>SIGCOMM CCR 2023 The Slow Path Needs an Accelerator Too! Annus Zulfiqar, Ben Pfaff, William Tu, Gianni Antichi, Muhammad Shahbaz</p>"},{"location":"userguide/configuration/","title":"Project Configuration","text":""},{"location":"userguide/configuration/#testbed-configuration","title":"Testbed Configuration","text":"<p>We use Ansible to orcherstrate all experiments using these three machines. Therefore, we require <code>root</code> access to each of them. To populate for each machine, update the <code>inventory.ini</code> file as following:</p> inventory.ini<pre><code>[NODES]\nTGEN ansible_host=&lt;tgen-ip&gt; ansible_user=&lt;tgen-username&gt; ansible_password=&lt;tgen-password&gt; ansible_sudo_pass=&lt;tgen-root-password&gt;\nGVS ansible_host=&lt;ovs-ip&gt; ansible_user=&lt;ovs-username&gt; ansible_password=&lt;ovs-password&gt; ansible_sudo_pass=&lt;ovs-root-password&gt;\n\n[STORAGE]\nCOLLECTOR ansible_host=&lt;collector-ip&gt; ansible_user=&lt;collector-username&gt; ansible_password=&lt;collector-password&gt; ansible_sudo_pass=&lt;collector-root-password&gt; ansible_ssh_user=&lt;collector-username&gt; ansible_ssh_pass=&lt;collector-root-password&gt;\n</code></pre>"},{"location":"userguide/configuration/#experiment-specific-configuration","title":"Experiment-Specific Configuration","text":"<p>To setup and run a specific experiment (with a given locality, vSwitch pipeline, and Gigaflow tables configuration), modify the following variables in <code>vars/main.yml</code>.</p> vars/main.yml<pre><code># the locality (high/low) to pick the correct traffic\n# choose an option from locality_static\nlocality_dynamic:\n  current:\n    locality: \"high-locality\"\n\n# the pipeline to install and send traffic for\n# choose an option from pipelines_static\npipelines_dynamic: \n  current: \n    name: \"cord-ofdpa\"\n    sub_path: \"cord/ofdpa\"\n\n# the Gigaflow tables and entries limit in each of them\n# choose an option from gigaflow_static\ngigaflow_dynamic:\n  experiment: \"ee\" # this is just the name for the logs directory\n  options:\n      gigaflow_tables_limit: 4\n      gigaflow_max_entries: 8000\n</code></pre>"},{"location":"userguide/examples/","title":"Examples","text":""},{"location":"userguide/usage/","title":"Usage","text":"<ul> <li> <p>Start the Ansible docker by using the following command. Terminal<pre><code>make ansible\n</code></pre></p> </li> <li> <p>Test connectivity between all three machines: Ansible Terminal<pre><code>make ping\n</code></pre></p> </li> </ul> <p>Run all the following commands from within this Ansible docker container.</p>"},{"location":"userguide/usage/#run-all-experiments","title":"Run All Experiments","text":"<p>To setup and run all end-to-end and microbenchmark experiments, run the following sequence of commands:</p> Ansible Terminal<pre><code># retrieve rulesets and traffic from COLLECTOR and place them on OVS and TGEN\n# this will also install gvs (gvs with Gigaflow), the traffic generator, and all their dependencies\nmake setup-gvs-experiment\n\n# run end-to-end (ee) experiments and microbenchmarks (bm)\n# and loop over all the available rulesets and microbenchmark configurations\n# and for each of them, setup the switch and traffic generators, send/receive the traffic\n# and collect OVS/TGEN logs and place them on the COLLECTOR machine\nmake run-gvs-experiment\n\n# teardown the experiment: this will uninstall gvs and tgen and clear logs from local machines; logs will remain saved on the COLLECTOR machine\nmake teardown-gvs-experiment\n</code></pre>"},{"location":"userguide/usage/#run-end-to-end-experiments","title":"Run End-to-End Experiments","text":"<p>To setup and run only end-to-end experiments:</p> Ansible Terminal<pre><code># retrieve rulesets and traffic from COLLECTOR and place them on OVS and TGEN\n# this will also install gvs (gvs with Gigaflow), the traffic generator, and all their dependencies\nmake setup-gvs-experiment\n\n# run end-to-end (ee) experiments and microbenchmarks (bm)\n# and loop over all the available rulesets and for each of them, setup the switch and traffic generators, send/receive the traffic\n# and collect OVS/TGEN logs and place them on the COLLECTOR machine\nmake run-gvs-ee-experiment\n\n# teardown the experiment: this will uninstall gvs and tgen and clear logs from local machines; logs will remain saved on the COLLECTOR machine\nmake teardown-gvs-experiment\n</code></pre>"},{"location":"userguide/usage/#run-microbenchmarks","title":"Run Microbenchmarks","text":"<p>To setup and run only microbenchmark experiments:</p> Ansible Terminal<pre><code># retrieve rulesets and traffic from COLLECTOR and place them on OVS and TGEN\n# this will also install gvs (gvs with Gigaflow), the traffic generator, and all their dependencies\nmake setup-gvs-experiment\n\n# run end-to-end (ee) experiments and microbenchmarks (bm)\n# and loop over all the available rulesets and for each of them, setup the switch and traffic generators, send/receive the traffic\n# and collect OVS/TGEN logs and place them on the COLLECTOR machine\nmake run-gvs-bm-experiment\n\n# teardown the experiment: this will uninstall gvs and tgen and clear logs from local machines; logs will remain saved on the COLLECTOR machine\nmake teardown-gvs-experiment\n</code></pre>"},{"location":"userguide/usage/#run-specific-experiment-for-one-vswitch-pipeline","title":"Run Specific Experiment for One vSwitch Pipeline","text":"<p>To setup and run a specific experiment (with a given locality, pipeline, and Gigaflow tables configuration), modify the following variables in <code>vars/main.yml</code>.</p> vars/main.yml<pre><code># the locality (high/low) to pick the correct traffic\n# choose an option from locality_static\nlocality_dynamic:\n  current:\n    locality: \"high-locality\"\n\n# the pipeline to install and send traffic for\n# choose an option from pipelines_static\npipelines_dynamic: \n  current: \n    name: \"cord-ofdpa\"\n    sub_path: \"cord/ofdpa\"\n\n# the Gigaflow tables and entries limit in each of them\n# choose an option from gigaflow_static\ngigaflow_dynamic:\n  experiment: \"ee\" # this is just the name for the logs directory\n  options:\n      gigaflow_tables_limit: 4\n      gigaflow_max_entries: 8000\n</code></pre> <p>Once these variables are setup, run the following sequence of commands. </p> Ansible Terminal<pre><code># sync the pipelines/traffic from COLLECTOR to NODES\nmake install-dataset \n\n# install the switch (with dependencies)\nmake install-gvs \n\n# install the traffic generators (with dependencies)\nmake install-tgen\n\n# start the gigaflow-virtual-switch\n# and install the pipeline rules in the switch\nmake start-switch-gvs \nmake install-rules\n\n# start the traffic (this will stop automatically)\nmake start-tgen\n\n# cleanup after the traffic is sent\nmake stop-tgen\n\n# uninstall the rules from the switch and stop it\nmake uninstall-rules \nmake stop-switch-gvs\n\n# copy logs from gvs and tgen to the collector machine\nmake collect-logs\n\n# uninstall the tgen, gvs, and delete datasets\nmake uninstall-tgen \nmake uninstall-gvs \nmake uninstall-dataset\n</code></pre>"}]}